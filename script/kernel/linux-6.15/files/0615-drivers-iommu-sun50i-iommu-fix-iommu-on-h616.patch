diff --speed-large-files --no-dereference --minimal -Naur linux-6.11.3/drivers/iommu/sun50i-iommu.c linux-6.11.3/drivers/iommu/sun50i-iommu.c
--- linux-6.11.3/drivers/iommu/sun50i-iommu.c	2024-10-16 15:48:57.183358884 +0200
+++ linux-6.11.3/drivers/iommu/sun50i-iommu.c	2024-10-16 15:47:20.116691895 +0200
@@ -452,7 +452,8 @@
 		    IOMMU_TLB_PREFETCH_MASTER_ENABLE(3) |
 		    IOMMU_TLB_PREFETCH_MASTER_ENABLE(4) |
 		    IOMMU_TLB_PREFETCH_MASTER_ENABLE(5));
-	iommu_write(iommu, IOMMU_BYPASS_REG, 0);
+	iommu_write(iommu, 0x84, 0);
+	iommu_write(iommu, 0x30, 0);
 	iommu_write(iommu, IOMMU_INT_ENABLE_REG, IOMMU_INT_MASK);
 	iommu_write(iommu, IOMMU_DM_AUT_CTRL_REG(SUN50I_IOMMU_ACI_NONE),
 		    IOMMU_DM_AUT_CTRL_RD_UNAVAIL(SUN50I_IOMMU_ACI_NONE, 0) |
@@ -527,14 +528,15 @@
 	dma_addr_t pt_dma;
 	u32 *page_table;
 
-	page_table = kmem_cache_zalloc(iommu->pt_pool, gfp);
+	page_table = (u32 *)__get_free_pages(GFP_KERNEL | __GFP_ZERO | GFP_DMA32,
+					     get_order(PT_SIZE));
 	if (!page_table)
 		return ERR_PTR(-ENOMEM);
 
 	pt_dma = dma_map_single(iommu->dev, page_table, PT_SIZE, DMA_TO_DEVICE);
 	if (dma_mapping_error(iommu->dev, pt_dma)) {
 		dev_err(iommu->dev, "Couldn't map L2 Page Table\n");
-		kmem_cache_free(iommu->pt_pool, page_table);
+		free_pages((unsigned long)page_table, get_order(PT_SIZE));
 		return ERR_PTR(-ENOMEM);
 	}
 
@@ -550,7 +552,7 @@
 	phys_addr_t pt_phys = virt_to_phys(page_table);
 
 	dma_unmap_single(iommu->dev, pt_phys, PT_SIZE, DMA_TO_DEVICE);
-	kmem_cache_free(iommu->pt_pool, page_table);
+	free_pages((unsigned long)page_table, get_order(PT_SIZE));
 }
 
 static u32 *sun50i_dte_get_page_table(struct sun50i_iommu_domain *sun50i_domain,
@@ -604,14 +606,6 @@
 
 	pages = size / SPAGE_SIZE;
 
-	/* the IOMMU can only handle 32-bit addresses, both input and output */
-	if ((uint64_t)paddr >> 32) {
-		ret = -EINVAL;
-		dev_warn_once(iommu->dev,
-			      "attempt to map address beyond 4GB\n");
-		goto out;
-	}
-
 	page_table = sun50i_dte_get_page_table(sun50i_domain, iova, gfp);
 	if (IS_ERR(page_table)) {
 		ret = PTR_ERR(page_table);
@@ -698,8 +692,7 @@
 	if (!sun50i_domain)
 		return NULL;
 
-	sun50i_domain->dt = iommu_alloc_pages(GFP_KERNEL | GFP_DMA32,
-					      get_order(DT_SIZE));
+	sun50i_domain->dt = iommu_alloc_pages(GFP_KERNEL | GFP_DMA32, get_order(DT_SIZE));
 	if (!sun50i_domain->dt)
 		goto err_free_domain;
 
@@ -1012,13 +1005,6 @@
 	platform_set_drvdata(pdev, iommu);
 	iommu->dev = &pdev->dev;
 
-	iommu->pt_pool = kmem_cache_create(dev_name(&pdev->dev),
-					   PT_SIZE, PT_SIZE,
-					   SLAB_HWCACHE_ALIGN | SLAB_CACHE_DMA32,
-					   NULL);
-	if (!iommu->pt_pool)
-		return -ENOMEM;
-
 	iommu->base = devm_platform_ioremap_resource(pdev, 0);
 	if (IS_ERR(iommu->base)) {
 		ret = PTR_ERR(iommu->base);
